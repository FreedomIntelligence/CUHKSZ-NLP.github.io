---
---

@article{zhang2018quantum,
  title={A quantum-inspired multimodal sentiment analysis framework},
  author={Zhang, Yazhou and Song, Dawei and Zhang, Peng and Wang, Panpan and Li, Jingfei and Li, Xiang and Wang, Benyou},
  journal={Theoretical Computer Science},
  volume={752},
  pages={21--40},
  year={2018},
  publisher={Elsevier}
}

@article{wang2019semantic,
  title={Semantic Hilbert Space for Text Representation Learning},
  author={Wang, Benyou and Li, Qiuchi and Melucci, Massimo and Song, Dawei},
  journal={WWW 2019},
  year={2019}
}

@article{zhao2019leveraging,
  title={Leveraging Long and Short-Term Information in Content-Aware Movie Recommendation via Adversarial Training},
  author={Zhao*, Wei and Wang*, Benyou and Yang, Min and Ye, Jianbo and Zhao, Zhou and Chen, Xiaojun and Shen, Ying},
  journal={IEEE transactions on cybernetics},
  year={2019},
  publisher={IEEE}
}

@article{li2019cnm,
  title={CNM: An Interpretable Complex-valued Network for Matching},
  author={Li*, Qiuchi and Wang*, Benyou and Melucci, Massimo},
  journal={NAACL 2019. Best Explainable NLP Paper},
  year={2019}
}

@inproceedings{wang2019dynamic,
  title={Dynamic content monitoring and exploration using vector spaces},
  author={Wang, Benyou},
  booktitle={Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1444--1444},
  year={2019}
}

@incollection{wang2019representing,
  title={Representing Words in vector space and beyond},
  author={Wang, Benyou and Buccio, Emanuele Di and Melucci, Massimo},
  booktitle={Quantum-Like Models for Information Retrieval and Decision-Making},
  pages={83--113},
  year={2019},
  publisher={Springer International Publishing Cham}
}

@article{wang2019encoding,
  title={Encoding word order in complex embeddings},
  author={Wang, Benyou and Zhao, Donghao and Lioma, Christina and Li, Qiuchi and Zhang, Peng and Simonsen, Jakob Grue},
  journal={ICLR 2020 Spotlight},
  year={2019}
}

@inproceedings{wang2020position,
  title={On position embeddings in bert},
  author={Wang, Benyou and Shang, Lifeng and Lioma, Christina and Jiang, Xin and Yang, Hao and Liu, Qun and Simonsen, Jakob Grue},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{zhang2021cfn,
  title={CFN: a complex-valued fuzzy network for sarcasm detection in conversations},
  author={Zhang, Yazhou and Liu, Yaochen and Li, Qiuchi and Tiwari, Prayag and Wang, Benyou and Li, Yuhua and Pandey, Hari Mohan and Zhang, Peng and Song, Dawei},
  journal={IEEE Transactions on Fuzzy Systems},
  volume={29},
  number={12},
  pages={3696--3710},
  year={2021},
  publisher={IEEE}
}

@article{wang2021pre,
  title={Pre-trained Language Models in Biomedical Domain: A Survey from Multiscale Perspective},
  author={Wang, Benyou and Xie, Qianqian and Pei, Jiahuan and Tiwari, Prayag and Li, Zhao and Jie, Fu},
  journal={arXiv preprint arXiv:2110.05006},
  year={2021}
}

@article{wang2021word2fun,
  title={Word2Fun: Modelling Words as Functions for Diachronic Word Representation},
  author={Wang, Benyou and Di Buccio, Emanuele and Melucci, Massimo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={2861--2872},
  year={2021}
}

@inproceedings{wang2022exploring,
  title={Exploring extreme parameter compression for pre-trained language models},
  author={Wang, Benyou and Ren, Yuxin and Shang, Lifeng and Jiang, Xin and Liu, Qun},
  booktitle={ICLR 2022},
  year={2022}
}

@article{zhang2022complex,
  title={Complex-valued Neural Network-based Quantum Language Models},
  author={Zhang, Peng and Hui, Wenjie and Wang*, Benyou and Zhao, Donghao and Song, Dawei and Lioma, Christina and Grue Simonsen, Jakob},
  journal={ACM Transactions on Information Systems},
  volume={40},
  number={4},
  pages={1--31},
  year={2022},
  publisher={ACM}
}

@article{tang2022dptdr,
  title={DPTDR: Deep Prompt Tuning for Dense Passage Retrieval},
  author={Tang, Zhengyang and Wang, Benyou and Yao, Ting},
  journal={COLING 2022},
  year={2022}
}

@article{yang2022doge,
  title={Doge Tickets: Uncovering Domain-general Language Models by Playing Lottery Tickets},
  author={Yang, Yi and Zhang, Chen and Wang, Benyou and Song, Dawei},
  journal={NLPCC 2022 Best Paper},
  year={2022}
}

@article{wang2023can,
  title={Can Language Models Make Fun? A Case Study in Chinese Comical Crosstalk},
  author={Wang, Benyou and Wu, Xiangbo and Liu, Xiaokang and Li, Jianquan and Tiwari, Prayag and Xie, Qianqian},
  journal={ACL 2023},
  year={2023}
}

@article{gan2022morphte,
  title={MorphTE: Injecting Morphology in Tensorized Embeddings},
  author={Gan, Guobing and Zhang, Peng and Li, Sunzhu and Lu, Xiuqing and Wang, Benyou},
  journal={NeurIPS 2022},
  year={2022}
}

@article{li2023adapting,
  title={Adapting Pre-trained Language Models for Quantum Natural Language Processing},
  author={Li, Qiuchi and Wang, Benyou and Zhu, Yudong and Lioma, Christina and Liu, Qun},
  journal={arXiv preprint arXiv:2302.13812},
  year={2023}
}

@article{han2022document,
  title={Document-level Relation Extraction with Relation Correlations},
  author={Han, Ridong and Peng, Tao and Wang, Benyou and Liu, Lu and Wan, Xiang},
  journal={arXiv preprint arXiv:2212.10171},
  year={2022}
}

@inproceedings{li2022hypoformer,
  title={Hypoformer: Hybrid decomposition transformer for edge-friendly neural machine translation},
  author={Li, Sunzhu and Zhang, Peng and Gan, Guobing and Lv, Xiuqing and Wang, Benyou and Wei, Junqiu and Jiang, Xin},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={7056--7068},
  year={2022}
}

@article{chen2023towards,
  title={Towards Unifying Medical Vision-and-Language Pre-training via Soft Prompts},
  author={Chen, Zhihong and Diao, Shizhe and Wang, Benyou and Li, Guanbin and Wan, Xiang},
  journal={ICCV 2023},
  year={2023}
}

@article{liang2023modular,
  title={Modular Retrieval for Generalization and Interpretation},
  author={Liang, Juhao and Zhang, Chen and Tang, Zhengyang and Fu, Jie and Song, Dawei and Wang, Benyou},
  journal={arXiv preprint arXiv:2303.13419},
  year={2023}
}

@article{xie2023survey,
  title={A Survey on Biomedical Text Summarization with Pre-trained Language Model},
  author={Xie, Qianqian and Luo, Zheheng and Wang, Benyou and Ananiadou, Sophia},
  journal={arXiv preprint arXiv:2304.08763},
  year={2023}
}

@inproceedings{liu2023effective,
  title={Effective Open Intent Classification with K-center Contrastive Learning and Adjustable Decision Boundary},
  author={Liu, Xiaokang and Li, Jianquan and Mu, Jingjing and Yang, Min and Xu, Ruifeng and Wang, Benyou},
  booktitle={AAAI},
  year={2023}
}

@article{chen2023phoenix,
  title={Phoenix: Democratizing chatgpt across languages},
  author={Chen, Zhihong and Jiang, Feng and Chen, Junying and Wang, Tiannan and Yu, Fei and Chen, Guiming and Zhang, Hongbo and Liang, Juhao and Zhang, Chen and Zhang, Zhiyi and others},
  journal={arXiv preprint arXiv:2304.10453},
  year={2023},
  arxiv={2304.10453},
  code={https://github.com/FreedomIntelligence/LLMZoo}
}

@article{zhang2023lifting,
  title={Lifting the Curse of Capacity Gap in Distilling Language Models},
  author={Zhang, Chen and Yang, Yang and Liu, Jiahao and Wang, Jingang and Xian, Yunsen and Wang, Benyou and Song, Dawei},
  journal={ACL 2023},
  year={2023}
}

@article{liu2023one,
  title={One Cannot Stand for Everyone! Leveraging Multiple User Simulators to train Task-oriented Dialogue Systems},
  author={LIU, Yajiao and Jiang, Xin and Yin, Yichun and Wang, Yasheng and Mi, Fei and Liu, Qun and Wan, Xiang and Wang, Benyou},
  journal={ACL 2023},
  year={2023}
}

@article{chen2023difference,
  title={On the Difference of BERT-style and CLIP-style Text Encoders},
  author={Chen, Zhihong and Chen, Guiming Hardy and Diao, Shizhe and Wan, Xiang and Wang, Benyou},
  journal={ACL 2023 findings},
  year={2023}
}

@article{sun2023few,
  title={Few-Shot Class-Incremental Learning for Medical Time Series Classification},
  author={Sun, Le and Zhang, Mingyang and Wang, Benyou and Tiwari, Prayag},
  journal={IEEE Journal of Biomedical and Health Informatics},
  year={2023},
  publisher={IEEE}
}

@article{yu2023nature,
  title={Natural language reasoning, a survey},
  author={Yu, Fei and Zhang, Hongbo and Wang, Benyou},
  journal={arXiv preprint arXiv:2303.14725},
  year={2023}
}

@article{li2023huatuo,
  title={Huatuo-26M, a Large-scale Chinese Medical QA Dataset},
  author={Li, Jianquan and Wang, Xidong and Wu, Xiangbo and Zhang, Zhiyi and Xu, Xiaolong and Fu, Jie and Tiwari, Prayag and Wan, Xiang and Wang, Benyou},
  journal={arXiv preprint arXiv:2305.01526},
  year={2023},
  arxiv={2305.01526},
  code={https://github.com/FreedomIntelligence/Huatuo-26M}
}

@article{han2023information,
  title={Is Information Extraction Solved by ChatGPT? An Analysis of Performance, Evaluation Criteria, Robustness and Errors},
  author={Han, Ridong and Peng, Tao and Yang, Chaohao and Wang, Benyou and Liu, Lu and Wan, Xiang},
  journal={arXiv preprint arXiv:2305.14450},
  year={2023},
  arxiv={2305.14450}
  code={https://github.com/FreedomIntelligence/Evaluation-of-ChatGPT-on-Information-Extraction},
  
}

@article{zhang2023huatuogpt,
  title={HuatuoGPT, towards Taming Language Model to Be a Doctor},
  author={Zhang, Hongbo and Chen, Junying and Jiang, Feng and Yu, Fei and Chen, Zhihong and Li, Jianquan and Chen, Guiming and Wu, Xiangbo and Zhang, Zhiyi and Xiao, Qingying and others},
  journal={arXiv preprint arXiv:2305.15075},
  year={2023},
  arxiv={2305.15075},
  code={https://github.com/FreedomIntelligence/HuatuoGPT}
}

@article{zhang2023injecting,
  title={Injecting Knowledge into Biomedical Pre-trained Models via Polymorphism and Synonymous Substitution},
  author={Zhang, Hongbo and Wan, Xiang and Wang, Benyou},
  journal={arXiv preprint arXiv:2305.15010},
  year={2023}
}

@article{wang2023cmb,
  title={CMB: A Comprehensive Medical Benchmark in Chinese},
  author={Wang, Xidong and Chen, Guiming Hardy and Song, Dingjie and Zhang, Zhiyi and Chen, Zhihong and Xiao, Qingying and Jiang, Feng and Li, Jianquan and Wan, Xiang and Wang, Benyou and others},
  journal={arXiv preprint arXiv:2308.08833},
  year={2023},
  arxiv={2308.08833},
  code={https://github.com/FreedomIntelligence/CMB}
}

@article{kong2023large,
  title={Large Language Model as a User Simulator},
  author={Kong, Chuyi and Fan, Yaxin and Wan, Xiang and Jiang, Feng and Wang, Benyou},
  journal={arXiv preprint arXiv:2308.11534},
  year={2023},
  arxiv={2308.11534}
  code={https://github.com/FreedomIntelligence/ReaLM}
}
